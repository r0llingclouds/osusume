{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anilist_old import get_media_by_id\n",
    "from IPython.display import display, Image, HTML\n",
    "\n",
    "# Test with Cowboy Bebop (ID: 1)\n",
    "anime = get_media_by_id(1)\n",
    "\n",
    "# Display basic information\n",
    "print(f\"Title: {anime['title']['english']} ({anime['title']['romaji']})\")\n",
    "print(f\"Episodes: {anime['episodes']}\")\n",
    "print(f\"Year: {anime['seasonYear']}\")\n",
    "print(f\"Score: {anime['averageScore']}\")\n",
    "print(f\"Genres: {', '.join(anime['genres'])}\")\n",
    "\n",
    "# Display cover image if available\n",
    "if 'coverImage' in anime and anime['coverImage'].get('large'):\n",
    "    display(Image(url=anime['coverImage']['large']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anilist_old import search_anime\n",
    "\n",
    "# Search for \"Attack on Titan\"\n",
    "search_results = search_anime(\"danberu\", limit=5)\n",
    "\n",
    "# Print results\n",
    "for anime in search_results:\n",
    "    title = anime['title']['english'] or anime['title']['romaji']\n",
    "    print(f\"- {title} (ID: {anime['id']}, Score: {anime['averageScore']})\")\n",
    "    print(f\"  Genres: {', '.join(anime['genres'])}\")\n",
    "    print(f\"  Year: {anime['seasonYear']}, Episodes: {anime['episodes']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anilist_old import get_popular_anime\n",
    "\n",
    "# Get top 5 popular anime\n",
    "popular_anime = get_popular_anime(per_page=5)\n",
    "\n",
    "# Create a simple table\n",
    "print(\"Top 5 Most Popular Anime:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Title':<40} {'Year':<10} {'Score':<10} {'Popularity':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for anime in popular_anime:\n",
    "    title = anime['title']['english'] or anime['title']['romaji']\n",
    "    print(f\"{title[:38]:<40} {anime['seasonYear']:<10} {anime['averageScore']:<10} {anime['popularity']:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anilist_old import get_seasonal_anime\n",
    "\n",
    "# Get top anime from Winter 2024\n",
    "seasonal_anime = get_seasonal_anime(2025, \"WINTER\")\n",
    "\n",
    "# Print results\n",
    "for i, anime in enumerate(seasonal_anime, 1):\n",
    "    title = anime['title']['english'] or anime['title']['romaji']\n",
    "    status = anime['status']\n",
    "    score = anime['averageScore'] or \"N/A\"\n",
    "    print(f\"{i}. {title}\")\n",
    "    print(f\"   Status: {status}, Score: {score}\")\n",
    "    print(f\"   Genres: {', '.join(anime['genres'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anilist_old import get_anime_by_genre\n",
    "\n",
    "# Get top \"Romance\" anime\n",
    "romance_anime = get_anime_by_genre(\"Ecchi\", per_page=5)\n",
    "\n",
    "# Print results\n",
    "for i, anime in enumerate(romance_anime, 1):\n",
    "    title = anime['title']['english'] or anime['title']['romaji']\n",
    "    year = anime['seasonYear'] or \"N/A\"\n",
    "    score = anime['averageScore'] or \"N/A\"\n",
    "    print(f\"{i}. {title} ({year})\")\n",
    "    print(f\"   Score: {score}, Format: {anime['format']}\")\n",
    "    print(f\"   Genres: {', '.join(anime['genres'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anilist_old import fetch_from_anilist\n",
    "\n",
    "def get_anime_by_tags(tags, page=1, per_page=20):\n",
    "    \"\"\"\n",
    "    Get anime by tags\n",
    "    \n",
    "    Args:\n",
    "        tags (list): List of tags to search for\n",
    "        page (int): Page number\n",
    "        per_page (int): Results per page\n",
    "        \n",
    "    Returns:\n",
    "        list: List of anime matching the tags\n",
    "    \"\"\"\n",
    "    query = '''\n",
    "    query ($tags: [String], $page: Int, $perPage: Int) {\n",
    "        Page(page: $page, perPage: $perPage) {\n",
    "            media(type: ANIME, tag_in: $tags, sort: POPULARITY_DESC) {\n",
    "                id\n",
    "                title {\n",
    "                    romaji\n",
    "                    english\n",
    "                }\n",
    "                genres\n",
    "                tags {\n",
    "                    id\n",
    "                    name\n",
    "                    rank\n",
    "                    isMediaSpoiler\n",
    "                }\n",
    "                averageScore\n",
    "                episodes\n",
    "                format\n",
    "                seasonYear\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    \n",
    "    variables = {\n",
    "        \"tags\": tags,\n",
    "        \"page\": page,\n",
    "        \"perPage\": per_page\n",
    "    }\n",
    "    \n",
    "    response = fetch_from_anilist(query, variables)\n",
    "    return response['data']['Page']['media']\n",
    "\n",
    "# Get anime with \"Time Travel\" and \"Psychological\" tags\n",
    "search_results = get_anime_by_tags([\"isekai\"], per_page=5)\n",
    "\n",
    "# Print results\n",
    "for anime in search_results:\n",
    "    title = anime['title']['english'] or anime['title']['romaji']\n",
    "    genres = anime['genres']\n",
    "    tags = [tag['name'] for tag in anime['tags']]\n",
    "    print(f\"- {title}\")\n",
    "    print(f\"  Genres: {', '.join(genres)}\")\n",
    "    print(f\"  Tags: {', '.join(tags)}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anilist_old import get_anime_recommendations\n",
    "\n",
    "# Get recommendations for \"Death Note\" (ID: 1535)\n",
    "source, recommendations = get_anime_recommendations(1535)\n",
    "\n",
    "# Print results\n",
    "source_title = source['title']['english'] or source['title']['romaji']\n",
    "print(f\"Recommendations for '{source_title}':\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, anime in enumerate(recommendations, 1):\n",
    "    title = anime['title']['english'] or anime['title']['romaji']\n",
    "    score = anime['averageScore'] or \"N/A\"\n",
    "    year = anime['seasonYear'] or \"N/A\"\n",
    "    print(f\"{i}. {title} ({year})\")\n",
    "    print(f\"   Score: {score}\")\n",
    "    print(f\"   Genres: {', '.join(anime['genres'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anilist_old import get_anime_characters_and_staff\n",
    "\n",
    "# Get characters and staff for \"Fullmetal Alchemist: Brotherhood\" (ID: 5114)\n",
    "anime_details = get_anime_characters_and_staff(5114)\n",
    "\n",
    "# Print results\n",
    "title = anime_details['title']['english'] or anime_details['title']['romaji']\n",
    "print(f\"Characters and Staff for '{title}':\")\n",
    "\n",
    "# Print characters\n",
    "print(\"\\nMain Characters:\")\n",
    "print(\"-\" * 50)\n",
    "for i, character in enumerate(anime_details['characters']['nodes'], 1):\n",
    "    name = character['name']['full']\n",
    "    gender = character['gender'] or \"Unknown\"\n",
    "    print(f\"{i}. {name} (Gender: {gender})\")\n",
    "    if character['description']:\n",
    "        desc = character['description'].replace(\"<br>\", \" \")[:100]\n",
    "        print(f\"   {desc}...\")\n",
    "    print()\n",
    "\n",
    "# Print staff\n",
    "print(\"\\nStaff:\")\n",
    "print(\"-\" * 50)\n",
    "for i, person in enumerate(anime_details['staff']['nodes'], 1):\n",
    "    name = person['name']['full']\n",
    "    occupations = \", \".join(person['primaryOccupations'][:2]) if person['primaryOccupations'] else \"Unknown\"\n",
    "    print(f\"{i}. {name}\")\n",
    "    print(f\"   Occupation: {occupations}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anilist_old import search_anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Basic title search (replaces original search_anime)\n",
    "results = search_anime(search_term=\"Attack on Titan\", per_page=5)\n",
    "print(f\"Found {len(results)} results for 'Attack on Titan'\")\n",
    "for anime in results:\n",
    "    print(f\"- {anime['title']['english'] or anime['title']['romaji']} ({anime['seasonYear']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Find seasonal anime (replaces get_seasonal_anime)\n",
    "winter_2023 = search_anime(season=\"WINTER\", year=2025)\n",
    "print(f\"\\nTop anime from Winter 2023:\")\n",
    "for anime in winter_2023[:5]:  # Just show top 5\n",
    "    print(f\"- {anime['title']['english'] or anime['title']['romaji']} \" \n",
    "          f\"(Score: {anime['averageScore']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Search by genre (replaces get_anime_by_genre)\n",
    "action_anime = search_anime(genre=\"Action\", per_page=10)\n",
    "\n",
    "for anime in action_anime:\n",
    "    print(f\"- {anime['title']['english'] or anime['title']['romaji']} ({anime['seasonYear']})\")\n",
    "    print(f\"  Genres: {', '.join(anime['genres'])}\")\n",
    "    print(f\"  Tags: {', '.join([tag['name'] for tag in anime['tags']])}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3b: Search by genre (replaces get_anime_by_genre)\n",
    "action_comedy = search_anime(genres=[\"Action\", \"Comedy\"], per_page=10)\n",
    "\n",
    "for anime in action_comedy:\n",
    "    print(f\"- {anime['title']['english'] or anime['title']['romaji']} ({anime['seasonYear']})\")\n",
    "    print(f\"  Genres: {', '.join(anime['genres'])}\")\n",
    "    print(f\"  Tags: {', '.join([tag['name'] for tag in anime['tags']])}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psychological_thriller = search_anime(tags=[\"Isekai\"], per_page=10)\n",
    "\n",
    "for anime in psychological_thriller:\n",
    "    print(f\"- {anime['title']['english'] or anime['title']['romaji']} ({anime['seasonYear']})\")\n",
    "    print(f\"  Genres: {', '.join(anime['genres'])}\")\n",
    "    print(f\"  Tags: {', '.join([tag['name'] for tag in anime['tags']])}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5: Combined search (new capability)\n",
    "# Find romance anime from Summer 2022 with school setting\n",
    "summer_romance = search_anime(\n",
    "    season=\"SUMMER\",\n",
    "    year=2022,\n",
    "    genre=\"Romance\",\n",
    "    tags=[\"School\"],\n",
    "    per_page=10\n",
    ")\n",
    "\n",
    "for anime in summer_romance:\n",
    "    print(f\"- {anime['title']['english'] or anime['title']['romaji']} ({anime['seasonYear']})\")\n",
    "    print(f\"  Genres: {', '.join(anime['genres'])}\")\n",
    "    print(f\"  Tags: {', '.join([tag['name'] for tag in anime['tags']])}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 6: Different sorting options\n",
    "# Sort by score instead of popularity\n",
    "top_rated = search_anime(genre=\"Fantasy\", sort=\"SCORE_DESC\", per_page=5)\n",
    "print(\"\\nTop rated Fantasy anime:\")\n",
    "for anime in top_rated:\n",
    "    print(f\"- {anime['title']['english'] or anime['title']['romaji']} \"\n",
    "          f\"(Score: {anime['averageScore']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 7: Pagination example\n",
    "# Get second page of results for a query\n",
    "page_2 = search_anime(genre=\"Slice of Life\", page=2, per_page=10)\n",
    "print(f\"\\nSlice of Life anime (page 2): {len(page_2)} results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 8: Processing results - Get average score by genre\n",
    "def get_genre_stats(genre_name, year=None):\n",
    "    anime_list = search_anime(genre=genre_name, year=year, per_page=50)\n",
    "    scores = [a['averageScore'] for a in anime_list if a['averageScore']]\n",
    "    if not scores:\n",
    "        return {\"genre\": genre_name, \"avg_score\": None, \"count\": 0}\n",
    "    return {\n",
    "        \"genre\": genre_name,\n",
    "        \"avg_score\": sum(scores) / len(scores),\n",
    "        \"count\": len(anime_list),\n",
    "        \"top_anime\": anime_list[0]['title']['english'] or anime_list[0]['title']['romaji']\n",
    "    }\n",
    "\n",
    "genres = [\"Romance\", \"Horror\", \"Comedy\", \"Action\"]\n",
    "genre_stats = [get_genre_stats(g, year=2023) for g in genres]\n",
    "print(\"\\nGenre statistics for 2023:\")\n",
    "for stat in genre_stats:\n",
    "    if stat[\"avg_score\"]:\n",
    "        print(f\"- {stat['genre']}: Average score {stat['avg_score']:.1f} from {stat['count']} anime\")\n",
    "    else:\n",
    "        print(f\"- {stat['genre']}: No data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"based_on\": \"How Heavy Are the Dumbbells You Lift?\",\n",
      "  \"genres_matched\": [\n",
      "    \"Comedy\",\n",
      "    \"Ecchi\"\n",
      "  ],\n",
      "  \"recommendations\": [\n",
      "    {\n",
      "      \"title\": \"KONOSUBA -God's blessing on this wonderful world!- Legend of Crimson\",\n",
      "      \"score\": 83,\n",
      "      \"episodes\": 1\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"KONOSUBA -God's blessing on this wonderful world! 3\",\n",
      "      \"score\": 82,\n",
      "      \"episodes\": 11\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"KONOSUBA -God's blessing on this wonderful world! 2\",\n",
      "      \"score\": 81,\n",
      "      \"episodes\": 10\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"My Dress-Up Darling\",\n",
      "      \"score\": 80,\n",
      "      \"episodes\": 12\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"The 100 Girlfriends Who Really, Really, Really, Really, REALLY Love You Season 2\",\n",
      "      \"score\": 80,\n",
      "      \"episodes\": 12\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def get_recommendations(favorite_anime_title, limit=5):\n",
    "    \"\"\"Recommend anime based on a favorite title\"\"\"\n",
    "    # First, find the favorite anime to get its genres and tags\n",
    "    search_results = search_anime(search_term=favorite_anime_title, per_page=1)\n",
    "    if not search_results:\n",
    "        return []\n",
    "    \n",
    "    reference_anime = search_results[0]\n",
    "    reference_genres = reference_anime['genres'][:2]  # Use top 2 genres\n",
    "    \n",
    "    # Find similar anime with the same genres but exclude the original\n",
    "    similar_anime = search_anime(\n",
    "        genres=reference_genres,\n",
    "        sort=\"SCORE_DESC\",\n",
    "        per_page=limit + 1  # Get extra in case we need to filter out the reference\n",
    "    )\n",
    "    \n",
    "    # Filter out the reference anime from results\n",
    "    recommendations = [anime for anime in similar_anime \n",
    "                      if anime['id'] != reference_anime['id']][:limit]\n",
    "    \n",
    "    return {\n",
    "        \"based_on\": reference_anime['title']['english'] or reference_anime['title']['romaji'],\n",
    "        \"genres_matched\": reference_genres,\n",
    "        \"recommendations\": [\n",
    "            {\n",
    "                \"title\": anime['title']['english'] or anime['title']['romaji'],\n",
    "                \"score\": anime['averageScore'],\n",
    "                \"episodes\": anime['episodes']\n",
    "            }\n",
    "            for anime in recommendations\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "recommendations = get_recommendations(\"dumbbell nan kilo moteru\")\n",
    "print(json.dumps(recommendations, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Find anime that are both Fantasy and Adventure genres with Magic tag\n",
    "fantasy_adventure_magic = search_anime(\n",
    "    genres=[\"Hentai\"],\n",
    "    tags=[\"Isekai\"],\n",
    "    per_page=10\n",
    ")\n",
    "\n",
    "print(f\"Found {len(fantasy_adventure_magic)} results\")\n",
    "for anime in fantasy_adventure_magic:\n",
    "    print(f\"- {anime['title']['english'] or anime['title']['romaji']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Find horror mystery anime with psychological elements\n",
    "horror_psychological = search_anime(\n",
    "    genres=[\"Horror\", \"Hentai\"],\n",
    "    tags=[],\n",
    "    sort=\"SCORE_DESC\",\n",
    "    per_page=10\n",
    ")\n",
    "\n",
    "print(\"\\nHorror/Mystery anime with Psychological elements:\")\n",
    "for anime in horror_psychological:\n",
    "    print(f\"- {anime['title']['english'] or anime['title']['romaji']} \" \n",
    "          f\"(Score: {anime['averageScore']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Find romance comedy anime in a school setting\n",
    "romcom_school = search_anime(\n",
    "    genres=[\"Romance\", \"Comedy\"],\n",
    "    tags=[\"School\"],\n",
    "    season=\"SPRING\",  # Optional: add season filter\n",
    "    year=2023,        # Optional: add year filter\n",
    "    per_page=15\n",
    ")\n",
    "\n",
    "print(\"\\nRomance comedies set in school:\")\n",
    "for anime in romcom_school:\n",
    "    print(f\"- {anime['title']['english'] or anime['title']['romaji']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Find sci-fi anime with both mecha and space tags\n",
    "scifi_mecha_space = search_anime(\n",
    "    genres=[\"Sci-Fi\", \"Space\"],  # Using single genre parameter\n",
    "    per_page=10\n",
    ")\n",
    "\n",
    "print(\"\\nSci-Fi anime with both mecha and space elements:\")\n",
    "for anime in scifi_mecha_space:\n",
    "    print(f\"- {anime['title']['english'] or anime['title']['romaji']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Find sci-fi anime with both mecha and space tags\n",
    "search_results = search_anime(\n",
    "    genres=[\"Isekai\", \"Ecchi\"],  # Using single genre parameter\n",
    "    tags=[],\n",
    "    per_page=5\n",
    ")\n",
    "\n",
    "# get from the results those that have all genres in the list\n",
    "search_results = [anime for anime in search_results if all(genre in anime['genres'] for genre in [\"Isekai\", \"Ecchi\"])]\n",
    "print(f\"Found {len(search_results)} results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All results:\n",
      "- How Heavy Are the Dumbbells You Lift?\n",
      "  Genres: Comedy, Ecchi, Slice of Life, Sports\n",
      "  Tags: Fitness, Educational, Athletics, Female Protagonist, Urban, Primarily Female Cast, Episodic, Tomboy, Bar, Tanned Skin, Boxing, Cute Girls Doing Cute Things, Gyaru, Parody, Meta, Shounen, Large Breasts, Food, Teacher, Nudity, Cosplay, School\n",
      "------------------------------------------------------------\n",
      "- Keijo!!!!!!!!\n",
      "  Genres: Comedy, Ecchi, Sports\n",
      "  Tags: Primarily Female Cast, Parody, Female Protagonist, Shounen, Fitness, Super Power, Nudity, School, Yuri, Primarily Teen Cast, Tomboy, Delinquents, Martial Arts, Dissociative Identities\n",
      "------------------------------------------------------------\n",
      "- Air Gear\n",
      "  Genres: Action, Comedy, Ecchi, Sports\n",
      "  Tags: Male Protagonist, Shounen, Delinquents, Urban, Gangs, Coming of Age, Parkour, Kuudere, Dissociative Identities, School, Nudity\n",
      "------------------------------------------------------------\n",
      "- Harukana Receive\n",
      "  Genres: Ecchi, Slice of Life, Sports\n",
      "  Tags: Volleyball, Primarily Female Cast, Coastal, Female Protagonist, Cute Girls Doing Cute Things, Outdoor Activities, School Club, Twins, Seinen\n",
      "------------------------------------------------------------\n",
      "- Walkure Romanze\n",
      "  Genres: Ecchi, Romance, Sports\n",
      "  Tags: Female Harem, Teacher, Primarily Teen Cast, Outdoor Activities, Female Protagonist, Heterosexual, School, Male Protagonist, Primarily Female Cast, Work, Animals, Maids, Nudity, Foreign, Ojou-sama, Kuudere, CGI, Educational, Cute Girls Doing Cute Things, Meta\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example 4: Find sci-fi anime with both mecha and space tags\n",
    "search_results = search_anime(\n",
    "    genres=[\"Sports\", \"Ecchi\"],  # Using single genre parameter\n",
    "    # tags=[\"Isekai\", \"Female Harem\", \"Aliens\"],\n",
    "    per_page=5\n",
    ")\n",
    "\n",
    "# # Print all results first\n",
    "print(\"All results:\")\n",
    "for anime in search_results:\n",
    "    print(f\"- {anime['title']['english'] or anime['title']['romaji']}\")\n",
    "    print(f\"  Genres: {', '.join(anime['genres'])}\")\n",
    "    print(f\"  Tags: {', '.join([tag['name'] for tag in anime['tags']])}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All five of them hit all three tags—Sci‑Fi, Isekai and Female Harem:\n",
      "\n",
      "• Sword Art Online II  \n",
      "• Combatants Will Be Dispatched!  \n",
      "• Hybrid × Heart Magias Academy Ataraxia  \n",
      "• Freezing  \n",
      "• Cross Ange: Rondo of Angel and Dragon\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"o4-mini\",\n",
    "    input=\"Which one of these anime has all of these tags: \" + \", \".join(keywords) + \"?\" + \"Here are the results: \" + results\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action', 'Adventure', 'Comedy', 'Drama', 'Ecchi', 'Fantasy', 'Hentai', 'Horror', 'Mahou Shoujo', 'Mecha', 'Music', 'Mystery', 'Psychological', 'Romance', 'Sci-Fi', 'Slice of Life', 'Sports', 'Supernatural', 'Thriller']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the GraphQL query to fetch media genres\n",
    "query = '''\n",
    "query ($page: Int, $perPage: Int) {\n",
    "  Page(page: $page, perPage: $perPage) {\n",
    "    media(type: ANIME) {\n",
    "      genres\n",
    "    }\n",
    "  }\n",
    "}\n",
    "'''\n",
    "\n",
    "# Function to fetch genres from a specific page\n",
    "def fetch_genres(page, per_page=50):\n",
    "    url = 'https://graphql.anilist.co'\n",
    "    variables = {'page': page, 'perPage': per_page}\n",
    "    response = requests.post(url, json={'query': query, 'variables': variables})\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    media_list = data['data']['Page']['media']\n",
    "    genres = set()\n",
    "    for media in media_list:\n",
    "        for genre in media['genres']:\n",
    "            genres.add(genre)\n",
    "    return genres\n",
    "\n",
    "# Accumulate genres from multiple pages\n",
    "all_genres = set()\n",
    "num_pages = 5  # Adjust the number of pages as needed\n",
    "for page in range(1, num_pages + 1):\n",
    "    page_genres = fetch_genres(page)\n",
    "    all_genres.update(page_genres)\n",
    "\n",
    "# Output the sorted list of unique genres\n",
    "print(sorted(all_genres))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request for ID 36870 failed with status code 404\n",
      "Request for ID 127632 failed with status code 404\n",
      "Request for ID 123832 failed with status code 404\n",
      "Request for ID 140760 failed with status code 404\n",
      "Request for ID 43814 failed with status code 404\n",
      "Request for ID 108311 failed with status code 404\n",
      "Request for ID 126078 failed with status code 404\n",
      "Request for ID 175178 failed with status code 404\n",
      "Request for ID 152086 failed with status code 404\n",
      "Request for ID 102802 failed with status code 404\n",
      "Request for ID 5679 failed with status code 404\n",
      "Request for ID 29704 failed with status code 404\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m valid_ids, \u001b[38;5;28msorted\u001b[39m(all_genres)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m ids, genres = \u001b[43mfetch_random_genres\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.75\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mValid IDs found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mids\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     44\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCollected genres: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenres\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[92]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mfetch_random_genres\u001b[39m\u001b[34m(sample_size, delay_seconds)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(sample_size):\n\u001b[32m     20\u001b[39m     anime_id = random.randint(\u001b[32m1\u001b[39m, \u001b[32m180000\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttps://graphql.anilist.co\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvariables\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43manime_id\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# Check for successful response\u001b[39;00m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/osusume/.venv/lib/python3.11/site-packages/requests/api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/osusume/.venv/lib/python3.11/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/osusume/.venv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/osusume/.venv/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/osusume/.venv/lib/python3.11/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    664\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    682\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/osusume/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/osusume/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/osusume/.venv/lib/python3.11/site-packages/urllib3/connection.py:516\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    513\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    519\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1395\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1394\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1395\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1396\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1397\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:325\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:286\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fp.readline(_MAXLINE + \u001b[32m1\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    288\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py:718\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    720\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1314\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1312\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1313\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.11/3.11.11/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1166\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1165\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Define the GraphQL query for fetching an anime by ID\n",
    "query = '''\n",
    "query ($id: Int) {\n",
    "  Media(id: $id, type: ANIME) {\n",
    "    id\n",
    "    genres\n",
    "  }\n",
    "}\n",
    "'''\n",
    "\n",
    "def fetch_random_genres(sample_size=50, delay_seconds=0.75):\n",
    "    all_genres = set()\n",
    "    valid_ids = []\n",
    "\n",
    "    for _ in range(sample_size):\n",
    "        anime_id = random.randint(1, 180000)\n",
    "        response = requests.post(\n",
    "            'https://graphql.anilist.co',\n",
    "            json={'query': query, 'variables': {'id': anime_id}}\n",
    "        )\n",
    "\n",
    "        # Check for successful response\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            media = data.get('data', {}).get('Media')\n",
    "            if media and media.get('genres'):\n",
    "                all_genres.update(media['genres'])\n",
    "                valid_ids.append(anime_id)\n",
    "        else:\n",
    "            print(f\"Request for ID {anime_id} failed with status code {response.status_code}\")\n",
    "\n",
    "        # Add delay to avoid rate limiting\n",
    "        time.sleep(delay_seconds)\n",
    "\n",
    "    return valid_ids, sorted(all_genres)\n",
    "\n",
    "# Usage\n",
    "ids, genres = fetch_random_genres(100, delay_seconds=0.75)\n",
    "print(f\"Valid IDs found: {ids}\")\n",
    "print(f\"Collected genres: {genres}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comprehensive Genre List: ['Action', 'Adventure', 'Comedy', 'Drama', 'Ecchi', 'Fantasy', 'Hentai', 'Horror', 'Mahou Shoujo', 'Mecha', 'Music', 'Mystery', 'Psychological', 'Romance', 'Sci-Fi', 'Slice of Life', 'Sports', 'Supernatural', 'Thriller']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "\n",
    "def get_all_genres_via_seasons():\n",
    "    query = '''\n",
    "    query ($season: MediaSeason, $seasonYear: Int, $page: Int, $perPage: Int) {\n",
    "        Page(page: $page, perPage: $perPage) {\n",
    "            media(season: $season, seasonYear: $seasonYear, type: ANIME) {\n",
    "                genres\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    \n",
    "    seasons = ['WINTER', 'SPRING', 'SUMMER', 'FALL']\n",
    "    years = range(2015, 2025)  # Last decade of anime\n",
    "    genre_set = set()\n",
    "    \n",
    "    for year in years:\n",
    "        for season in seasons:\n",
    "            page = 1\n",
    "            while True:\n",
    "                response = requests.post(\n",
    "                    'https://graphql.anilist.co',\n",
    "                    json={\n",
    "                        'query': query,\n",
    "                        'variables': {\n",
    "                            'season': season,\n",
    "                            'seasonYear': year,\n",
    "                            'page': page,\n",
    "                            'perPage': 50\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                if response.status_code != 200:\n",
    "                    break\n",
    "                \n",
    "                media_list = response.json()['data']['Page']['media']\n",
    "                if not media_list:\n",
    "                    break\n",
    "                \n",
    "                for media in media_list:\n",
    "                    if media['genres']:\n",
    "                        genre_set.update(media['genres'])\n",
    "                \n",
    "                # Pagination control\n",
    "                if len(media_list) < 50:\n",
    "                    break\n",
    "                page += 1\n",
    "                sleep(0.67)  # Respect 90 RPM rate limit\n",
    "    \n",
    "    return sorted(genre_set)\n",
    "\n",
    "# Execution\n",
    "genres = get_all_genres_via_seasons()\n",
    "print(\"Comprehensive Genre List:\", genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('genres.json', 'w') as f:\n",
    "    json.dump(genres, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed for SUMMER 2017 page 2\n",
      "Request failed for FALL 2017 page 1\n",
      "Request failed for WINTER 2018 page 1\n",
      "Request failed for SPRING 2018 page 1\n",
      "Request failed for SUMMER 2018 page 1\n",
      "Request failed for FALL 2018 page 1\n",
      "Request failed for WINTER 2019 page 1\n",
      "Request failed for SPRING 2019 page 1\n",
      "Request failed for SUMMER 2019 page 1\n",
      "Request failed for FALL 2019 page 1\n",
      "Request failed for WINTER 2020 page 1\n",
      "Request failed for SPRING 2020 page 1\n",
      "Request failed for SUMMER 2020 page 1\n",
      "Request failed for FALL 2020 page 1\n",
      "Request failed for WINTER 2021 page 1\n",
      "Request failed for SPRING 2021 page 1\n",
      "Request failed for SUMMER 2021 page 1\n",
      "Request failed for FALL 2021 page 1\n",
      "Request failed for WINTER 2022 page 1\n",
      "Request failed for SPRING 2022 page 1\n",
      "Request failed for SUMMER 2022 page 1\n",
      "Request failed for FALL 2022 page 1\n",
      "Request failed for WINTER 2023 page 1\n",
      "Request failed for SPRING 2023 page 1\n",
      "Request failed for SUMMER 2023 page 1\n",
      "Request failed for FALL 2023 page 1\n",
      "Request failed for WINTER 2024 page 1\n",
      "Request failed for SPRING 2024 page 1\n",
      "Request failed for SUMMER 2024 page 1\n",
      "Request failed for FALL 2024 page 1\n",
      "Collected tags: ['4-koma', 'Achromatic', 'Achronological Order', 'Acting', 'Adoption', 'Advertisement', 'Afterlife', 'Age Gap', 'Age Regression', 'Agender', 'Agriculture', 'Ahegao', 'Airsoft', 'Alchemy', 'Aliens', 'Alternate Universe', 'American Football', 'Amnesia', 'Amputation', 'Anachronism', 'Anal Sex', 'Angels', 'Animals', 'Anthology', 'Anthropomorphism', 'Anti-Hero', 'Archery', 'Armpits', 'Aromantic', 'Arranged Marriage', 'Artificial Intelligence', 'Asexual', 'Ashikoki', 'Asphyxiation', 'Assassins', 'Astronomy', 'Athletics', 'Augmented Reality', 'Autobiographical', 'Aviation', 'Band', 'Bar', 'Baseball', 'Basketball', 'Battle Royale', 'Biographical', 'Bisexual', 'Blackmail', 'Board Game', 'Boarding School', 'Body Horror', 'Body Swapping', 'Bondage', 'Boobjob', 'Bowling', 'Boxing', \"Boys' Love\", 'Bullying', 'Butler', 'CGI', 'Calligraphy', 'Camping', 'Cannibalism', 'Card Battle', 'Cars', 'Centaur', 'Cheating', 'Cheerleading', 'Chibi', 'Chimera', 'Chuunibyou', 'Circus', 'Class Struggle', 'Classic Literature', 'Classical Music', 'Clone', 'Coastal', 'Cohabitation', 'College', 'Coming of Age', 'Conspiracy', 'Cosmic Horror', 'Cosplay', 'Cowboys', 'Creature Taming', 'Crime', 'Criminal Organization', 'Crossdressing', 'Crossover', 'Cult', 'Cultivation', 'Cumflation', 'Cunnilingus', 'Curses', 'Cute Boys Doing Cute Things', 'Cute Girls Doing Cute Things', 'Cyberpunk', 'Cyborg', 'Cycling', 'DILF', 'Dancing', 'Death Game', 'Deepthroat', 'Defloration', 'Delinquents', 'Demons', 'Denpa', 'Desert', 'Detective', 'Dinosaurs', 'Disability', 'Dissociative Identities', 'Double Penetration', 'Dragons', 'Drawing', 'Drugs', 'Dullahan', 'Dungeon', 'Dystopian', 'E-Sports', 'Eco-Horror', 'Economics', 'Educational', 'Elderly Protagonist', 'Elf', 'Ensemble Cast', 'Environmental', 'Episodic', 'Espionage', 'Estranged Family', 'Exhibitionism', 'Exorcism', 'Facial', 'Fairy', 'Fairy Tale', 'Fake Relationship', 'Family Life', 'Fashion', 'Feet', 'Fellatio', 'Female Harem', 'Female Protagonist', 'Femboy', 'Femdom', 'Fencing', 'Firefighters', 'Fishing', 'Fitness', 'Flash', 'Flat Chest', 'Food', 'Football', 'Foreign', 'Found Family', 'Fugitive', 'Full CGI', 'Futanari', 'Gambling', 'Gangs', 'Gender Bending', 'Ghost', 'Goblin', 'Gods', 'Gore', 'Group Sex', 'Guns', 'Gyaru', 'Handball', 'Handjob', 'Henshin', 'Heterosexual', 'Hikikomori', 'Hip-hop Music', 'Historical', 'Homeless', 'Horticulture', 'Human Pet', 'Hypersexuality', 'Ice Skating', 'Idol', 'Incest', 'Inn', 'Inseki', 'Irrumatio', 'Isekai', 'Iyashikei', 'Josei', 'Judo', 'Kaiju', 'Karuta', 'Kemonomimi', 'Kids', 'Kingdom Management', 'Kuudere', 'LGBTQ+ Themes', 'Lacrosse', 'Lactation', 'Language Barrier', 'Large Breasts', 'Lost Civilization', 'Love Triangle', 'MILF', 'Mafia', 'Magic', 'Mahjong', 'Maids', 'Makeup', 'Male Harem', 'Male Protagonist', 'Marriage', 'Martial Arts', 'Masochism', 'Masturbation', 'Matriarchy', 'Medicine', 'Medieval', 'Memory Manipulation', 'Mermaid', 'Meta', 'Metal Music', 'Military', 'Mixed Gender Harem', 'Mixed Media', 'Monster Boy', 'Monster Girl', 'Mopeds', 'Motorcycles', 'Musical Theater', 'Mythology', 'Nakadashi', 'Natural Disaster', 'Necromancy', 'Nekomimi', 'Netorare', 'Netorase', 'Netori', 'Ninja', 'No Dialogue', 'Noir', 'Nudity', 'Nun', 'Office', 'Office Lady', 'Oiran', 'Ojou-sama', 'Orphan', 'Otaku Culture', 'Outdoor Activities', 'POV', 'Pandemic', 'Parenthood', 'Parkour', 'Parody', 'Pet Play', 'Philosophy', 'Photography', 'Pirates', 'Poker', 'Police', 'Politics', 'Polyamorous', 'Post-Apocalyptic', 'Pregnancy', 'Primarily Adult Cast', 'Primarily Animal Cast', 'Primarily Child Cast', 'Primarily Female Cast', 'Primarily Male Cast', 'Primarily Teen Cast', 'Prison', 'Prostitution', 'Proxy Battle', 'Psychosexual', 'Public Sex', 'Puppetry', 'Rakugo', 'Rape', 'Real Robot', 'Rehabilitation', 'Reincarnation', 'Religion', 'Restaurant', 'Revenge', 'Rimjob', 'Robots', 'Rock Music', 'Rotoscoping', 'Royal Affairs', 'Rugby', 'Rural', 'Sadism', 'Samurai', 'Satire', 'Scat', 'School', 'School Club', 'Scissoring', 'Scuba Diving', 'Seinen', 'Sex Toys', 'Shapeshifting', 'Ships', 'Shogi', 'Shoujo', 'Shounen', 'Shrine Maiden', 'Skateboarding', 'Skeleton', 'Slapstick', 'Slavery', 'Snowscape', 'Software Development', 'Space', 'Space Opera', 'Spearplay', 'Squirting', 'Steampunk', 'Stop Motion', 'Succubus', 'Suicide', 'Sumata', 'Super Power', 'Super Robot', 'Superhero', 'Surfing', 'Surreal Comedy', 'Survival', 'Sweat', 'Swimming', 'Swordplay', 'Table Tennis', 'Tanks', 'Tanned Skin', 'Teacher', \"Teens' Love\", 'Tennis', 'Tentacles', 'Terrorism', 'Threesome', 'Time Loop', 'Time Manipulation', 'Time Skip', 'Tokusatsu', 'Tomboy', 'Torture', 'Tragedy', 'Trains', 'Transgender', 'Travel', 'Tsundere', 'Twins', 'Unrequited Love', 'Urban', 'Urban Fantasy', 'VTuber', 'Vampire', 'Video Games', 'Vikings', 'Villainess', 'Virginity', 'Virtual World', 'Vocal Synth', 'Volleyball', 'Voyeur', 'War', 'Watersports', 'Werewolf', 'Wilderness', 'Witch', 'Work', 'Wrestling', 'Writing', 'Wuxia', 'Yakuza', 'Yandere', 'Youkai', 'Yuri', 'Zombie']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "\n",
    "def get_all_tags_via_seasons():\n",
    "    query = '''\n",
    "    query ($season: MediaSeason, $seasonYear: Int, $page: Int, $perPage: Int) {\n",
    "        Page(page: $page, perPage: $perPage) {\n",
    "            media(season: $season, seasonYear: $seasonYear, type: ANIME) {\n",
    "                tags {\n",
    "                    name\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    \n",
    "    seasons = ['WINTER', 'SPRING', 'SUMMER', 'FALL']\n",
    "    years = range(2015, 2025)  # Adjust as needed\n",
    "    tag_set = set()\n",
    "    \n",
    "    for year in years:\n",
    "        for season in seasons:\n",
    "            page = 1\n",
    "            while True:\n",
    "                response = requests.post(\n",
    "                    'https://graphql.anilist.co',\n",
    "                    json={\n",
    "                        'query': query,\n",
    "                        'variables': {\n",
    "                            'season': season,\n",
    "                            'seasonYear': year,\n",
    "                            'page': page,\n",
    "                            'perPage': 50\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "                if response.status_code != 200:\n",
    "                    print(f\"Request failed for {season} {year} page {page}\")\n",
    "                    break\n",
    "                \n",
    "                data = response.json()\n",
    "                media_list = data['data']['Page']['media']\n",
    "                if not media_list:\n",
    "                    break\n",
    "                \n",
    "                for media in media_list:\n",
    "                    if media['tags']:\n",
    "                        for tag in media['tags']:\n",
    "                            tag_set.add(tag['name'])\n",
    "                \n",
    "                # Pagination control\n",
    "                if len(media_list) < 50:\n",
    "                    break\n",
    "                page += 1\n",
    "                sleep(0.67)  # Respect rate limit\n",
    "    \n",
    "    return sorted(tag_set)\n",
    "\n",
    "# Run the function and print all collected tags\n",
    "all_tags = get_all_tags_via_seasons()\n",
    "print(\"Collected tags:\", all_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed for SPRING 2018 page 3\n",
      "Request failed for SUMMER 2018 page 1\n",
      "Request failed for FALL 2018 page 1\n",
      "Request failed for WINTER 2019 page 1\n",
      "Request failed for SPRING 2019 page 1\n",
      "Request failed for SUMMER 2019 page 1\n",
      "Request failed for FALL 2019 page 1\n",
      "Request failed for WINTER 2020 page 1\n",
      "Request failed for SPRING 2020 page 1\n",
      "Request failed for SUMMER 2020 page 1\n",
      "Request failed for FALL 2020 page 1\n",
      "Request failed for WINTER 2021 page 1\n",
      "Request failed for SPRING 2021 page 1\n",
      "Request failed for SUMMER 2021 page 1\n",
      "Request failed for FALL 2021 page 1\n",
      "Request failed for WINTER 2022 page 1\n",
      "Request failed for SPRING 2022 page 1\n",
      "Request failed for SUMMER 2022 page 1\n",
      "Request failed for FALL 2022 page 1\n",
      "Request failed for WINTER 2023 page 1\n",
      "Request failed for SPRING 2023 page 1\n",
      "Request failed for SUMMER 2023 page 1\n",
      "Request failed for FALL 2023 page 1\n",
      "Request failed for WINTER 2024 page 1\n",
      "Request failed for SPRING 2024 page 1\n",
      "Request failed for SUMMER 2024 page 1\n",
      "Request failed for FALL 2024 page 1\n",
      "Collected tags: ['4-koma', 'Achromatic', 'Achronological Order', 'Acting', 'Adoption', 'Advertisement', 'Afterlife', 'Age Gap', 'Age Regression', 'Agender', 'Agriculture', 'Ahegao', 'Airsoft', 'Alchemy', 'Aliens', 'Alternate Universe', 'American Football', 'Amnesia', 'Amputation', 'Anachronism', 'Anal Sex', 'Angels', 'Animals', 'Anthology', 'Anthropomorphism', 'Anti-Hero', 'Archery', 'Armpits', 'Aromantic', 'Arranged Marriage', 'Artificial Intelligence', 'Asexual', 'Ashikoki', 'Asphyxiation', 'Assassins', 'Astronomy', 'Athletics', 'Augmented Reality', 'Autobiographical', 'Aviation', 'Badminton', 'Band', 'Bar', 'Baseball', 'Basketball', 'Battle Royale', 'Biographical', 'Bisexual', 'Blackmail', 'Board Game', 'Boarding School', 'Body Horror', 'Body Swapping', 'Bondage', 'Boobjob', 'Bowling', 'Boxing', \"Boys' Love\", 'Bullying', 'Butler', 'CGI', 'Calligraphy', 'Camping', 'Cannibalism', 'Card Battle', 'Cars', 'Centaur', 'Cheating', 'Cheerleading', 'Chibi', 'Chimera', 'Chuunibyou', 'Circus', 'Class Struggle', 'Classic Literature', 'Classical Music', 'Clone', 'Coastal', 'Cohabitation', 'College', 'Coming of Age', 'Conspiracy', 'Cosmic Horror', 'Cosplay', 'Cowboys', 'Creature Taming', 'Crime', 'Criminal Organization', 'Crossdressing', 'Crossover', 'Cult', 'Cultivation', 'Cumflation', 'Cunnilingus', 'Curses', 'Cute Boys Doing Cute Things', 'Cute Girls Doing Cute Things', 'Cyberpunk', 'Cyborg', 'Cycling', 'DILF', 'Dancing', 'Death Game', 'Deepthroat', 'Defloration', 'Delinquents', 'Demons', 'Denpa', 'Desert', 'Detective', 'Dinosaurs', 'Disability', 'Dissociative Identities', 'Double Penetration', 'Dragons', 'Drawing', 'Drugs', 'Dullahan', 'Dungeon', 'Dystopian', 'E-Sports', 'Eco-Horror', 'Economics', 'Educational', 'Elderly Protagonist', 'Elf', 'Ensemble Cast', 'Environmental', 'Episodic', 'Espionage', 'Estranged Family', 'Exhibitionism', 'Exorcism', 'Facial', 'Fairy', 'Fairy Tale', 'Fake Relationship', 'Family Life', 'Fashion', 'Feet', 'Fellatio', 'Female Harem', 'Female Protagonist', 'Femboy', 'Femdom', 'Fencing', 'Filmmaking', 'Firefighters', 'Fishing', 'Fitness', 'Flash', 'Flat Chest', 'Food', 'Football', 'Foreign', 'Found Family', 'Fugitive', 'Full CGI', 'Futanari', 'Gambling', 'Gangs', 'Gender Bending', 'Ghost', 'Goblin', 'Gods', 'Gore', 'Group Sex', 'Guns', 'Gyaru', 'Handball', 'Handjob', 'Henshin', 'Heterosexual', 'Hikikomori', 'Hip-hop Music', 'Historical', 'Homeless', 'Horticulture', 'Human Pet', 'Hypersexuality', 'Ice Skating', 'Idol', 'Incest', 'Indigenous Cultures', 'Inn', 'Inseki', 'Irrumatio', 'Isekai', 'Iyashikei', 'Josei', 'Judo', 'Kaiju', 'Karuta', 'Kemonomimi', 'Kids', 'Kingdom Management', 'Konbini', 'Kuudere', 'LGBTQ+ Themes', 'Lacrosse', 'Lactation', 'Language Barrier', 'Large Breasts', 'Lost Civilization', 'Love Triangle', 'MILF', 'Mafia', 'Magic', 'Mahjong', 'Maids', 'Makeup', 'Male Harem', 'Male Protagonist', 'Marriage', 'Martial Arts', 'Masochism', 'Masturbation', 'Matriarchy', 'Medicine', 'Medieval', 'Memory Manipulation', 'Mermaid', 'Meta', 'Metal Music', 'Military', 'Mixed Gender Harem', 'Mixed Media', 'Monster Boy', 'Monster Girl', 'Mopeds', 'Motorcycles', 'Mountaineering', 'Musical Theater', 'Mythology', 'Nakadashi', 'Natural Disaster', 'Necromancy', 'Nekomimi', 'Netorare', 'Netorase', 'Netori', 'Ninja', 'No Dialogue', 'Noir', 'Nudity', 'Nun', 'Office', 'Office Lady', 'Oiran', 'Ojou-sama', 'Orphan', 'Otaku Culture', 'Outdoor Activities', 'POV', 'Pandemic', 'Parenthood', 'Parkour', 'Parody', 'Pet Play', 'Philosophy', 'Photography', 'Pirates', 'Poker', 'Police', 'Politics', 'Polyamorous', 'Post-Apocalyptic', 'Pregnancy', 'Primarily Adult Cast', 'Primarily Animal Cast', 'Primarily Child Cast', 'Primarily Female Cast', 'Primarily Male Cast', 'Primarily Teen Cast', 'Prison', 'Prostitution', 'Proxy Battle', 'Psychosexual', 'Public Sex', 'Puppetry', 'Rakugo', 'Rape', 'Real Robot', 'Rehabilitation', 'Reincarnation', 'Religion', 'Restaurant', 'Revenge', 'Rimjob', 'Robots', 'Rock Music', 'Rotoscoping', 'Royal Affairs', 'Rugby', 'Rural', 'Sadism', 'Samurai', 'Satire', 'Scat', 'School', 'School Club', 'Scissoring', 'Scuba Diving', 'Seinen', 'Sex Toys', 'Shapeshifting', 'Ships', 'Shogi', 'Shoujo', 'Shounen', 'Shrine Maiden', 'Skateboarding', 'Skeleton', 'Slapstick', 'Slavery', 'Snowscape', 'Software Development', 'Space', 'Space Opera', 'Spearplay', 'Squirting', 'Steampunk', 'Stop Motion', 'Succubus', 'Suicide', 'Sumata', 'Super Power', 'Super Robot', 'Superhero', 'Surfing', 'Surreal Comedy', 'Survival', 'Sweat', 'Swimming', 'Swordplay', 'Table Tennis', 'Tanks', 'Tanned Skin', 'Teacher', \"Teens' Love\", 'Tennis', 'Tentacles', 'Terrorism', 'Threesome', 'Time Loop', 'Time Manipulation', 'Time Skip', 'Tokusatsu', 'Tomboy', 'Torture', 'Tragedy', 'Trains', 'Transgender', 'Travel', 'Tsundere', 'Twins', 'Unrequited Love', 'Urban', 'Urban Fantasy', 'VTuber', 'Vampire', 'Vertical Video', 'Video Games', 'Vikings', 'Villainess', 'Virginity', 'Virtual World', 'Vocal Synth', 'Volleyball', 'Vore', 'Voyeur', 'War', 'Watersports', 'Werewolf', 'Wilderness', 'Witch', 'Work', 'Wrestling', 'Writing', 'Wuxia', 'Yakuza', 'Yandere', 'Youkai', 'Yuri', 'Zombie']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from time import sleep\n",
    "\n",
    "def get_all_tags_via_seasons():\n",
    "    query = '''\n",
    "    query ($season: MediaSeason, $seasonYear: Int, $page: Int, $perPage: Int) {\n",
    "        Page(page: $page, perPage: $perPage) {\n",
    "            media(season: $season, seasonYear: $seasonYear, type: ANIME) {\n",
    "                tags {\n",
    "                    name\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    '''\n",
    "    \n",
    "    seasons = ['WINTER', 'SPRING', 'SUMMER', 'FALL']\n",
    "    years = range(2015, 2025)  # Adjust as needed\n",
    "    tag_set = set()\n",
    "    \n",
    "    for year in years:\n",
    "        for season in seasons:\n",
    "            page = 1\n",
    "            while True:\n",
    "                response = requests.post(\n",
    "                    'https://graphql.anilist.co',\n",
    "                    json={\n",
    "                        'query': query,\n",
    "                        'variables': {\n",
    "                            'season': season,\n",
    "                            'seasonYear': year,\n",
    "                            'page': page,\n",
    "                            'perPage': 50\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "                if response.status_code != 200:\n",
    "                    print(f\"Request failed for {season} {year} page {page}\")\n",
    "                    break\n",
    "                \n",
    "                data = response.json()\n",
    "                media_list = data['data']['Page']['media']\n",
    "                if not media_list:\n",
    "                    break\n",
    "                \n",
    "                for media in media_list:\n",
    "                    if media['tags']:\n",
    "                        for tag in media['tags']:\n",
    "                            tag_set.add(tag['name'])\n",
    "                \n",
    "                # Pagination control\n",
    "                if len(media_list) < 50:\n",
    "                    break\n",
    "                page += 1\n",
    "                sleep(2)  # Respect rate limit\n",
    "    \n",
    "    return sorted(tag_set)\n",
    "\n",
    "# Run the function and print all collected tags\n",
    "all_tags = get_all_tags_via_seasons()\n",
    "print(\"Collected tags:\", all_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as json\n",
    "import json\n",
    "with open('anime_tags.json', 'w') as f:\n",
    "    json.dump(all_tags, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
